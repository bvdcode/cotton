# SHCS-0001: Self-Hosted Cloud Storage (SHCS) Quality Classification

**Version:** 0.1

**Author:** Vadim Belov

**Intended audience:** authors and operators of self-hosted cloud storage systems

---

## 1. Purpose and Scope

This document defines a **classification standard for self-hosted cloud storage systems (SHCS)**.

The goal is:

- to give **technical buyers and admins** a clear way to compare systems beyond marketing checklists (“has WebDAV”, “has mobile app”);
- to give **authors of new systems** a concrete target for “what does _good_ look like” in terms of architecture, reliability and operations;
- to allow open-source projects to **self-declare a class** (A/B/C/D) using a shared vocabulary.

This standard is **descriptive, not prescriptive**:
it does not dictate implementation details, but defines **axes** and **classes** that capture how “industrial” a self-hosted cloud storage system really is.

The SHCS standard is explicitly about:

- **file and object storage** served over a network;
- **self-hosted deployments**, where the operator runs the server components.

It is **not** about:

- SaaS-only products;
- backup-only tools (e.g. pure rsync wrappers);
- single-user sync tools without multi-user/cloud semantics.

---

## 2. Terminology

- **SHCS** – Self-Hosted Cloud Storage, in this document both the standard and the class of systems it evaluates.
- **System** – a particular self-hosted cloud storage software stack (server and its official ecosystem).
- **Operator** – the person or team running the system on their own infrastructure.
- **Client** – any official desktop/mobile/web/sync client or protocol endpoint (e.g. WebDAV, S3 etc.).
- **User** – end-user who uses the system to store and access data.

Normative keywords **MUST**, **SHOULD**, **MAY** are used in the sense of RFC 2119.

---

## 3. What qualifies as an SHCS system

This standard applies to systems that meet **all** of the following:

1. **Self-hosted capability**
   The server software CAN be run by an operator on their own infrastructure (VM, bare metal, container, etc.).

2. **Multi-user cloud semantics**
   The system provides:
   - user accounts and authentication;
   - remote access via browser and/or protocols (WebDAV/S3-compatible/other).

3. **Persistent file/object storage**
   The system stores user data durably on disk or other persistent media, not merely in memory or as a temporary cache.

4. **File/folder-like abstraction for users**
   Users see their data via some form of hierarchy (folders, collections, libraries, etc.), not only as opaque IDs.

If any of these are missing, the software is **out of scope** for SHCS classification.

---

## 4. Evaluation Axes

Each conformant system is evaluated along **six axes**:

1. **SHCS-ARCH – Architecture & Storage Model**
2. **SHCS-PERF – Performance & Scaling**
3. **SHCS-DATA – Data Integrity & Cryptography**
4. **SHCS-UX – Predictability & User Experience**
5. **SHCS-OPS – Operations, Deployment & Upgrades**
6. **SHCS-ECO – Protocols, Clients & Ecosystem**

Each axis is scored from **0 to 3**:

- **3 – Industrial-grade**
- **2 – Solid / acceptable**
- **1 – Marginal / fragile**
- **0 – Not acceptable** (for anything calling itself “cloud storage”)

Below, each axis is defined with non-exhaustive criteria for 0/1/2/3.

---

### 4.1 SHCS-ARCH – Architecture & Storage Model

This axis evaluates **how the system is structured internally** and whether storage is a first-class, robust concept.

**Score 3 (Industrial-grade)** – system:

- Has a **clear and explicit storage model** (e.g. content-addressed chunks + manifests + layout, or another well-defined abstraction).
- Treats storage as a **first-class engine**, with the UI and APIs as clients of that engine.
- Uses a modern runtime and architecture which support concurrency, streaming I/O and long-term maintainability.
- Has well-documented invariants (e.g. “this ID is immutable”, “this mapping is always consistent”).

**Score 2 (Solid)** – system:

- Has a reasonably clear storage model (e.g. files + metadata in DB) and sticks to it.
- UI and storage are somewhat coupled, but not hopelessly entangled.
- Architecture allows for streaming and partial reads, even if not consistently used.

**Score 1 (Marginal)** – system:

- Is effectively a **thin wrapper over a filesystem**, with weak or ad-hoc modeling of metadata/content.
- UI/business logic heavily entangled with storage; changing one risks breaking the other.
- Lifetime/consistency guarantees are unclear or implicit.

**Score 0 (Not acceptable)** – system:

- Has no coherent storage model (ad-hoc paths, sidecar files, undocumented invariants).
- Depends on fragile, legacy architectural choices with no realistic path to fix them.

---

### 4.2 SHCS-PERF – Performance & Scaling

This axis evaluates **how the system behaves under load** and whether it was designed for realistic and worst-case scenarios.

**Score 3 (Industrial-grade)**:

- System demonstrably supports:
  - large directories / graphs (e.g. **10⁵–10⁶** items) without UI or API collapse;
  - large, continuous transfers (multi-GB) **without degrading** to “hundreds of KB/s”.

- Performance is **stable over time**: a transfer that starts fast stays fast until completion, assuming stable network and hardware.
- Design explicitly considers worst-case scenarios (very large trees, many small files, long-lived streams) and remains correct and usable there.

**Score 2 (Solid)**:

- System comfortably handles:
  - tens of thousands of items in a directory;
  - multi-GB transfers with minor or occasional slowdowns.

- Some operations may degrade under extreme load, but without corrupting metadata or hanging indefinitely.

**Score 1 (Marginal)**:

- System performs acceptably for small/medium workloads (e.g. a few thousand files, occasional large uploads).
- Under higher loads it frequently:
  - degrades to very low throughput,
  - blocks UI for long periods,
  - or requires manual tuning to stay usable.

**Score 0 (Not acceptable)**:

- Performance issues routinely make core operations (upload, list, browse) unusable under common conditions.
- The system cannot reliably complete large uploads or handle moderately large trees.

---

### 4.3 SHCS-DATA – Data Integrity & Cryptography

This axis evaluates **how seriously the system treats the safety of stored data**.

**Score 3 (Industrial-grade)**:

- Data integrity is actively verified:
  - content hashes or checksums computed and stored;
  - optional or periodic **sanity checks** that detect disk corruption or bitrot.

- Any cryptography (encryption-at-rest, E2EE, etc.) is:
  - integrated into the storage model,
  - designed with correct nonce/key semantics,
  - implemented using robust libraries.

- Partial failures (e.g. interrupted encryption/migration) do **not silently destroy or orphan data**; failures are fail-safe and well-signaled.

**Score 2 (Solid)**:

- Basic integrity protection exists:
  - checksums/hashes at REST or during transfer;
  - detection of mismatched content in common paths.

- Cryptography uses standard building blocks in a conventional way (e.g. FS-level encryption, library-based TLS) but may not be deeply integrated into the model.
- Some failure modes may cause data to become inaccessible, but only under uncommon conditions and usually with operator-visible errors.

**Score 1 (Marginal)**:

- Integrity is mostly delegated to the underlying filesystem/RAID.
- Any encryption is treated as a feature layer, not deeply integrated; documented failure modes may include data loss or confusion in partially completed operations.
- Operators must rely heavily on external tooling to detect corruption (e.g. ZFS scrub) rather than the application itself.

**Score 0 (Not acceptable)**:

- System has a history or design where encryption/migrations **routinely and silently** corrupt or lose user data.
- There is no meaningful integrity checking at the application level.

---

### 4.4 SHCS-UX – Predictability & User Experience

This axis is not about “prettiness” but about **predictability and responsiveness**.

**Score 3 (Industrial-grade)**:

- Core user actions have predictable outcomes:
  - uploading, renaming, deleting, moving items do exactly what the user expects;
  - no hidden heuristics “clean up” or “optimize” data behind the user’s back.

- The web UI remains responsive even for large trees:
  - virtualized lists, incremental loading, clear state feedback.

- Operations that may take a long time clearly communicate progress, errors and eventual success/failure.

**Score 2 (Solid)**:

- UI is generally usable and predictable under normal loads.
- Some operations may become sluggish on very large trees or under heavy concurrent use, but remain understandable and controllable.

**Score 1 (Marginal)**:

- UI frequently blocks or stalls for multiple seconds on everyday operations.
- Users encounter non-obvious behaviors (e.g. files disappearing due to space constraints or sync conflicts) that are not clearly explained.

**Score 0 (Not acceptable)**:

- Users cannot safely predict what will happen when they perform basic actions.
- UI freezes/hangs or produces inconsistent results as a normal occurrence.

---

### 4.5 SHCS-OPS – Operations, Deployment & Upgrades

This axis evaluates **how painful it is to run and maintain the system**.

**Score 3 (Industrial-grade)**:

- A minimal, production-viable deployment requires:
  - a small, well-defined set of services (e.g. app + DB + optional cache);
  - clear documentation and sane defaults.

- Upgrades are designed to be **automatic or one-command**, including schema migrations.
- The system surfaces actionable monitoring signals (logs, metrics) and fails loudly when invariants are broken.

**Score 2 (Solid)**:

- Deployment is well-documented and reasonably straightforward, even if several services are involved.
- Upgrades typically succeed but may require occasional manual intervention.
- Operators can recover from failed upgrades without major data loss.

**Score 1 (Marginal)**:

- Deployment requires manual stitching together of many components and undocumented assumptions.
- Upgrades are fragile and often require manual SQL/scripts or CLI tools; failures may leave the system in inconsistent states.
- Rollbacks are difficult.

**Score 0 (Not acceptable)**:

- Routine operations (deploy, upgrade) are unreliable, poorly documented, or known to break installations in unpredictable ways.

---

### 4.6 SHCS-ECO – Protocols, Clients & Ecosystem

This axis is about **how usable the system is in the real world**, beyond just the core engine.

**Score 3 (Industrial-grade)**:

- Multiple stable access paths exist:
  - web UI, at least one sync client (desktop or mobile), and common protocols (e.g. WebDAV, S3-compatible, or others).

- There is an active ecosystem:
  - plugins/integrations built on well-defined APIs;
  - documentation and examples for extending the system.

- Clients and integrations respect the core invariants and do not routinely compromise reliability.

**Score 2 (Solid)**:

- At least one mature client (desktop or mobile) and one standard protocol exist.
- Some extent of third-party tooling or integrations is available.
- APIs exist and are used in a limited but meaningful way.

**Score 1 (Marginal)**:

- Only web UI exists, or clients are experimental/unstable.
- Protocol support is narrow or unreliable.
- Ecosystem is minimal, extensions mostly live as “hacks”.

**Score 0 (Not acceptable)**:

- No real-world access paths beyond a basic web UI; no integrations, no documented APIs.

---

## 5. SHCS Classes

Given the 0–3 scores for each axis, an SHCS system is classified into one of four **classes**.

Let `A_arch`, `A_perf`, `A_data`, `A_ux`, `A_ops`, `A_eco` be the scores (0–3).
Let `M` be the arithmetic mean of all six.

### 5.1 Class A — Industrial-grade SHCS

A system is **SHCS Class A** if:

- `M ≥ 2.5`, and
- `A_perf ≥ 3` and `A_data ≥ 3`, and
- no axis is below `2`.

Informally: this is a **self-hosted cloud storage system suitable as a primary storage surface** for demanding use-cases, with:

- robust architecture,
- stable performance at high load,
- strong data integrity behavior,
- predictable UX,
- manageable operations.

### 5.2 Class B — Solid SHCS

A system is **SHCS Class B** if:

- `M ≥ 2.0`, and
- no axis is `0`.

Informally: this is a system that:

- is **safe to operate** for many scenarios;
- may have known limitations (e.g. perf on very large trees, weaker cryptographic integration, or limited ecosystem);
- but does not routinely endanger data or operator sanity.

### 5.3 Class C — Legacy / Heavyweight SHCS

A system is **SHCS Class C** if:

- `M ≥ 1.5`, and
- at least one axis is `1`, and none is `0`.

Informally: these are:

- heavy, legacy, or architecturally outdated systems that:
  - often have large ecosystems and many features,
  - but exhibit poor performance scaling, fragile upgrades, and/or weak data-integrity semantics.

They can be acceptable in some environments, but **do not represent modern standards** for self-hosted cloud storage design.

### 5.4 Class D — Experimental / Toy

A system is **SHCS Class D** if:

- it is in scope (Section 3), but
- `M < 1.5` or any of `A_perf`, `A_data` is `0` or `1`.

Informally: these are:

- prototypes,
- lab projects,
- tools which may be useful for niche or personal usage, but **should not be relied upon as core storage**.

---

## 6. Self-declaration and Transparency

Projects **MAY self-declare** an SHCS class if they:

1. Publish their axis scores (`A_arch` … `A_eco`) and resulting class.
2. Provide a short justification for each axis (1–3 bullet points).
3. Clearly mark the declaration as **self-assessed**.

Third-party reviews **SHOULD** use the same axes and scoring, and **SHOULD** explicitly state discrepancies with project self-assessment.

---

## 7. Security Considerations

Because SHCS systems operate on sensitive data, misclassification can have real consequences. Authors and reviewers **SHOULD** be conservative on:

- SHCS-DATA (integrity & crypto):
  any history of silent corruption, loss on migration, or broken encryption flows MUST be taken seriously.
- SHCS-PERF (perf & scaling):
  inability to complete large transfers or list large trees can indirectly endanger data (e.g. failed backups, partial restores).

An “Industrial-grade” (Class A) label implies a higher standard of care; projects SHOULD avoid claiming Class A unless they have:

- explicit tests or real-world deployments validating their claims;
- transparent handling of past data-loss or integrity issues.

---

## 8. Non-goals

SHCS deliberately does **not**:

- prescribe specific technologies (e.g. “must be content-addressed”, “must use Postgres”, etc.);
- require specific protocols (WebDAV vs S3 vs NFS), as long as at least one standard, interoperable path exists;
- mandate open-source licensing (although the standard is oriented toward open-source ecosystems).

The aim is a **neutral, implementation-agnostic framework** to talk about quality.
